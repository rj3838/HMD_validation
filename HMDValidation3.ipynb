{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 14:02:40,719 - HMDvalidation - INFO - Current directoryC:\\Users\\royja\\DataSpellProjects\\HMDvalidation\n",
      "2022-06-30 14:02:48,891 - HMDvalidation - INFO - Working with C:/Users/royja/DataSpellProjects/Hmd_Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RENFREWSHIRE RAV 2014.hmd']\n",
      "C:/Users/royja/DataSpellProjects/Hmd_Validation/RENFREWSHIRE RAV 2014.hmd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "# import sys\n",
    "from tkinter import filedialog\n",
    "\n",
    "# raw_file = open(os.path.normpath(\"C:/Users/rjaques/PycharmProjects/HMDvalidation/2145-04_Heathrow_SCANNER_2021Lane_1_CL.hmd\")\n",
    "# raw_file = open(os.path.normpath(\"G:/2019-20 SCANNER Data/WDM/Northern_Ireland/TNI RAV 2019- CL1.HMD\"),\n",
    "# raw_file = open(os.path.normpath(\"G:/2019-20 SCANNER Data/WDM/Wales/Torfaen/TORFAEN RAV 2019- CR1.HMD\"),\n",
    "# mode='r')\n",
    "\n",
    "# raw_hmdif = raw_file.readlines()\n",
    "# raw_file.close()\n",
    "\n",
    "logger = logging.getLogger('HMDvalidation')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(ch)\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "logger.info('Current directory' + curr_dir)\n",
    "\n",
    "file_path_variable = filedialog.askdirectory(initialdir=curr_dir, title='Please select a directory containing the data')\n",
    "\n",
    "if len(file_path_variable) > 0:\n",
    "    logger.info('Working with ' + file_path_variable)\n",
    "# return tempdir\n",
    "\n",
    "# file_list = os.listdir(file_path_variable)\n",
    "# file_list = glob.glob(file_path_variable)\n",
    "\n",
    "file_list = list()\n",
    "\n",
    "file_list += [each for each in os.listdir(file_path_variable) if each.endswith('.hmd')]\n",
    "\n",
    "print(file_list)\n",
    "\n",
    "\n",
    "# HMSTART check\n",
    "\n",
    "# check for only one HMSTART\n",
    "\n",
    "def line_counting(data_to_process, search_string):\n",
    "    # Counts the number of lines in a list with the search string in it.\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for line in data_to_process:\n",
    "        if search_string in line:\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "def record_testing(data_to_process, list_of_strings, correct_count):\n",
    "    # find out if the number of items in a list containing the string is the same as the correct_count\n",
    "\n",
    "    for field in list_of_strings:\n",
    "        if line_counting(data_to_process, field) != 1:\n",
    "            print(field + \" is missing\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def check_record_counts(start_string, end_string, file_to_check):\n",
    "    start_index = [i for i, item in enumerate(file_to_check) if item.startswith(start_string)][0]\n",
    "    end_index = [i for i, item in enumerate(file_to_check) if item.startswith(end_string)][0]\n",
    "\n",
    "    length_between_indexes = len(file_to_check[start_index:end_index]) + 1\n",
    "\n",
    "    res = re.findall(r'\\d+', (list(filter(lambda x: end_string in x, raw_hmdif))[0]))\n",
    "\n",
    "    # When the record count does not equal the value in the *END record shout...\n",
    "\n",
    "    if int(res[0]) != int(length_between_indexes):\n",
    "        print('The ' + end_string + ' record count is wrong')\n",
    "\n",
    "    #    print('Record count OK')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# for file in file_list:\n",
    "#    print(file)\n",
    "file = file_path_variable + \"/\" + file_list[0]\n",
    "\n",
    "print(file)\n",
    "# print(os.path.normpath(file[0]))\n",
    "raw_file = open(file, \"r\")\n",
    "\n",
    "raw_hmdif = raw_file.readlines()\n",
    "\n",
    "raw_file.close()\n",
    "\n",
    "list_of_records = ['HMSTART', 'TSTART', 'TEND', 'DSTART', 'DEND', 'HMEND']\n",
    "\n",
    "record_testing(raw_hmdif, list_of_records, 1)\n",
    "\n",
    "# check the record counts\n",
    "# using filter() + lambda\n",
    "# to get string with substring\n",
    "# res = re.findall(r'\\d+', (list(filter(lambda x: 'HMEND' in x, raw_hmdif))[0]))\n",
    "\n",
    "check_record_counts('HMSTART', 'HMEND', raw_hmdif)\n",
    "check_record_counts('TSTART', 'TEND', raw_hmdif)\n",
    "check_record_counts('DSTART', 'DEND', raw_hmdif)\n",
    "\n",
    "# check for only the values in the list_of_records\n",
    "\n",
    "raw_hmdif = [w.replace(';', '') for w in raw_hmdif]\n",
    "raw_hmdif = [w.replace('\\n', '') for w in raw_hmdif]\n",
    "# raw_hmdif = [w.replace('\\\\', '') for w in raw_hmdif]\n",
    "\n",
    "# find the DSTART index\n",
    "\n",
    "start_line = raw_hmdif.index('DSTART')\n",
    "\n",
    "# all the real data is after DSTART so :\n",
    "\n",
    "hmd_data = raw_hmdif[(start_line+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2141431\n"
     ]
    }
   ],
   "source": [
    "# print(len(hmd_data))\n",
    "\n",
    "# remove the control HMEND and DEND records\n",
    "\n",
    "hmd_data = hmd_data[:-2]\n",
    "\n",
    "print(len(hmd_data))\n",
    "\n",
    "list_out = list()\n",
    "el: str = \"\"\n",
    "survey: str = \"\"\n",
    "section: str = \"\"\n",
    "observation: str = \"\"\n",
    "\n",
    "#hmdif_df = pd.DataFrame(hmd_data)\n",
    "\n",
    "#print(len(hmdif_df))\n",
    "\n",
    "# list_out = list()\n",
    "# el: str\n",
    "# survey: str\n",
    "for el in hmd_data:\n",
    "    if el.split('\\\\')[0] == 'SURVEY':\n",
    "        survey = el.rsplit('\\\\', 1)[1]\n",
    "    if el.split('\\\\')[0] == 'SECTION':\n",
    "        section = el.rsplit('\\\\', 1)[1]\n",
    "    if el.split('\\\\')[0] == 'OBSERV':\n",
    "        observation = el.rsplit('\\\\', 1)[1]\n",
    "    if el.split('\\\\')[0] == 'OBVAL':\n",
    "        el = el.rsplit('\\\\', 1)[1]\n",
    "        # print(f\"{survey},{section},{observation},{el}\")\n",
    "        # list_out.append(survey,section,observation,el)\n",
    "        comma: str = \",\"\n",
    "        # seq = str()\n",
    "        line = ['SURVEY',',', survey,',','SECTION',',', section,',','OBSERV',',',observation,',','OBVAL',',',el]\n",
    "        seq = \" \".join(line)\n",
    "        # print(seq)\n",
    "        list_out.append(seq)\n",
    "        # print(len(list_out))\n",
    "\n",
    "hmdif_df = pd.DataFrame(list_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# split each record into dataframe columns based on the separating value being a ','\n",
    "hmdif_df2 = hmdif_df[0].str.split(',', expand=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# hmdifDF.columns = hmdifDF.iloc[0]\n",
    "hmdif_df2.columns = ['SURVEY', 'TYPE', 'VERSION', 'NUMBER', 'SUBSECT', 'MACHINE', 'XSPUSED',\n",
    "                     'OPERATOR1', 'OPERATOR2',\n",
    "                     'SECTION', 'LABEL', 'SNODE', 'LENGTH', 'SDATE',\n",
    "                     'EDATE', 'STIME', 'ETIME', 'OBSERV', 'DEFECT', 'XSECT', 'SCHAIN',\n",
    "                     'ECHAIN', 'OBVAL', 'PARM', 'OPTION', 'VALUE', 'PERCENT']\n",
    "# hmdifDF= hmdifDF[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "hmdif_df2['SCHAIN'] = hmdif_df2['SCHAIN'].astype('float')\n",
    "hmdif_df2['ECHAIN'] = hmdif_df2['ECHAIN'].astype('float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "short_df = hmdif_df2.drop(['SURVEY', 'TYPE', 'VERSION', 'NUMBER', 'SUBSECT',\n",
    "                           'SECTION', 'SNODE', 'STIME', 'ETIME', 'OBSERV', 'OBVAL'], axis=1)\n",
    "\n",
    "# short_df.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "short_df = short_df.round({'SCHAIN': -1, 'ECHAIN': -1})\n",
    "short_df.drop_duplicates(inplace=True)\n",
    "short_df['defect_parm'] = short_df['DEFECT'] + short_df['PARM']\n",
    "\n",
    "short_df.columns\n",
    "short_df2 = short_df.drop_duplicates(keep='last')\n",
    "\n",
    "#len(short_df)\n",
    "short_df2.drop(['XSPUSED', 'PARM', 'DEFECT'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dup_index = ['MACHINE', 'OPERATOR1', 'OPERATOR2', 'LABEL', 'LENGTH', 'SDATE',\n",
    "             'EDATE', 'XSECT', 'SCHAIN', 'ECHAIN', 'defect_parm']\n",
    "short_df3 = short_df2.drop_duplicates(subset=dup_index, keep='last')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pivot_index = ['MACHINE', 'OPERATOR1', 'OPERATOR2', 'LABEL', 'LENGTH', 'SDATE',\n",
    "               'EDATE', 'XSECT', 'SCHAIN', 'ECHAIN']\n",
    "pivot_values = ['VALUE']\n",
    "pivot_column = ['defect_parm']\n",
    "\n",
    "hmd_pivot = short_df3.pivot(index=pivot_index, columns=pivot_column, values=pivot_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['LCOO 30', 'LCOO 31', 'LCOO 32', 'LCRV 13', 'LCTM 13', 'LCTV 13',\n       'LECR 14', 'LEDC 14', 'LEDR 13', 'LES1 14', 'LES2 14', 'LFAL 14',\n       'LGRD 14', 'LL03 13', 'LL10 13', 'LLAD 13', 'LLBI 13', 'LLRD 13',\n       'LLRT 13', 'LLTD 13', 'LLTM 13', 'LLTV 13', 'LLTX 13', 'LMAP 2',\n       'LMAP 23', 'LMAP 24', 'LMAP 25', 'LOVD 14', 'LR03 13', 'LR10 13',\n       'LRAD 13', 'LRBI 13', 'LRCR 14', 'LRRD 13', 'LRRT 13', 'LRTM 13',\n       'LRTV 13', 'LSPD 13', 'LSUR 14', 'LT05 13', 'LT95 13', 'LTAD 13',\n       'LTRC 14', 'LTRV 13', 'LTVV 13', 'LV10 13', 'LV3 13', 'LV30 13',\n       'LWCL 14', 'LWCR 14'],\n      dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = hmd_pivot.columns\n",
    "\n",
    "# print(mi)\n",
    "\n",
    "ind = pd.Index([e[1].strip() for e in mi.tolist()])\n",
    "\n",
    "ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "param_list = ind.tolist()\n",
    "param_columns = pivot_index + param_list\n",
    "#param_columns.extend(param_list)\n",
    "#print(param_columns)\n",
    "#print(pivot_index.append(param_list.to_list()))\n",
    "#(fred.columns.map(lambda x: '_'.join([str(i) for i in x])))\n",
    "#(['%s%s' % (a, '|%s' % b if b else '') for a, b in fred.columns])\n",
    "#([f'{i}|{j}' if j != '' else f'{i}' for i,j in fred.columns])\n",
    "#fred.index = fred.index(axis=1).values\n",
    "#fred.index.map(lambda idx: f'{idx[2]}/{idx[1]}')\n",
    "#fred.reset_index(level = pivot_index)\n",
    "#fred.to_flat_index()\n",
    "#(fred.index.get_level_values(1))(fred.index.MultiIndex.nlevels)\n",
    "\n",
    "#print(fred.head)\n",
    "(hmd_pivot.reset_index(inplace=True))\n",
    "hmd_pivot.columns = param_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# i really want a copy...\n",
    "\n",
    "hmd_ffill2 = copy.copy(hmd_pivot)\n",
    "\n",
    "# cols = ['LCOO 30', 'LCOO 31', 'LCOO 32']\n",
    "\n",
    "hmd_ffill2.loc[:, param_list] = hmd_ffill2.loc[:, param_list].ffill(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "hmd_ffill = copy.copy(hmd_pivot)\n",
    "\n",
    "cols = ['LCOO 30', 'LCOO 31', 'LCOO 32']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\n",
    "#hmd_ffill.loc[:] = \\\n",
    "hmd_ffill.ffill(inplace=True,axis=0,limit=1)\n",
    "# hmd_ffill.loc[:,param_list].ffill(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "#hmd_ffill.loc[:,cols] = hmd_ffill.loc[:,cols].ffill(inplace=True)\n",
    "\n",
    "#hmd_ffill2 = hmd_ffill.loc[(hmd_ffill.SCHAIN == 0)]\n",
    "\n",
    "hmd_ffill['LCOO 30'] = np.where(hmd_ffill.SCHAIN == 0, np.nan, hmd_ffill['LCOO 30'])\n",
    "hmd_ffill['LCOO 31'] = np.where(hmd_ffill.SCHAIN == 0, np.nan, hmd_ffill['LCOO 31'])\n",
    "hmd_ffill['LCOO 32'] = np.where(hmd_ffill.SCHAIN == 0, np.nan, hmd_ffill['LCOO 32'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "# remove the rows where SCHAIN = ECHAIN\n",
    "hmd_ffill = hmd_ffill.loc[hmd_ffill['SCHAIN'] != hmd_ffill['ECHAIN']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#wait"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}